\section{Related Work}
\label{sec:related}

\paragraph{2D panoptic segmentation}
2D panoptic segmentation merges semantic and instance segmentation, providing detailed pixel-level parsing of images, capturing both general categories (semantic segmentation)
and individual object identities (instance segmentation) \citep{kirillov2019panoptic}. Since the original task formulation by \citet{kirillov2019panoptic}, a number of works
have been proposed to solve the task \cite{wang2020axial, cheng2020panoptic, mohan2021efficientps, Li_2021_CVPR, Wang_2021_CVPR, Li_2022_CVPR, Kundu_2022_CVPR, Cheng_2022_CVPR, Yu_2022_CVPR, Xu_2023_CVPR, Chen_2023_ICCV, li2023mask, yu2023convolutions},
while more recent approaches \citep{Jain_2023_CVPR} try to unify image segmentation in its entirety.

\paragraph{Single-view 3D reconstruction}
The work by \citet{snavely2006photo} was the first notable attempt at reconstructing 3D scenes from unordered photo collections. Since then, the field of image-based 3D reconstruction
has seen a number of advancements, culminating in the task of single-view 3D reconstruction \citep{choy20163d, wang2018pixel2mesh, mescheder2019occupancy, huang2019perspectivenet, shin20193d, denninger20203d, nie2020total3dunderstanding}.

\paragraph{Shape priors}
\citet{wu2018learning} note that the task of single-view 3D reconstruction is non-deterministic, as there are many 3D shapes that can explain a given single-view input, and propose
to use shape priors to shape the solution space such that the reconstructed shapes are realistic, but not necessarily the ground truth.

\paragraph{3D scene understanding and panoptic reconstruction}

\paragraph{Modality-conditioned shape generation}
3D generative models represent objects in a variety of modalities, including point clouds \citep{achlioptas2018learning, luo2021diffusion}, occupancy grids \citep{mescheder2019occupancy}, meshes \citep{mo2019structurenet}, and signed distance functions \citep{park2019deepsdf}.
Furthermore, these models can also be distinguished by the type of input they take, such as incomplete shapes \citep{dai2017shape}, images \citep{fan2017point}, text \citep{liu2022towards, zhao2023michelangelo}, or other modalities \citep{Zhou_2021_CVPR}. 
Notably, \citet{cheng2023sdfusion} propose \emph{SDFusion}, a method that can take image and text in addition to geometry as conditional input for 3D object generation.

\paragraph{DATASET}